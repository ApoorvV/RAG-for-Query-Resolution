{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Creating a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for PDF and subtitle processing, LangChain, and ChromaDB\n",
    "import pysrt\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from crewai import Agent, Task, Crew  \n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = 'your-api-key-here'\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 1: Helper Function to Process SRT Files ---\n",
    "\n",
    "def extract_text_from_srt(srt_path):\n",
    "    \"\"\"Extracts text from an SRT subtitle file using pysrt.\"\"\"\n",
    "    subs = pysrt.open(srt_path)\n",
    "    text = \" \".join(sub.text for sub in subs)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define course names and their respective folder paths\n",
    "# course_folders = {\n",
    "#     \"Introduction to Deep Learning using PyTorch\": \"/Users/apoorv/Desktop/AV/Code/GAI/AV_projects/Learners_Queries/Introduction_to_Deep_Learning_Using_Pytorch\",\n",
    "#     \"Building Production-Ready RAG systems using LlamaIndex\": \"/Users/apoorv/Desktop/AV/Code/GAI/AV_projects/Learners_Queries/Building Production-Ready RAG systems using LlamaIndex\",\n",
    "#     \"Introduction to LangChain - Building Generative AI Apps & Agents\": \"/Users/apoorv/Desktop/AV/Code/GAI/AV_projects/Learners_Queries/introduction_to_langchain_using_agentic_ai\"\n",
    "# }\n",
    "\n",
    "course_folders = {\n",
    "    \"Biology\": \"/Users/apoorv/Desktop/AV/Code/GAI/YT_projects/Query Resolution/Biology\",\n",
    "    \"Geography\": \"/Users/apoorv/Desktop/AV/Code/GAI/YT_projects/Query Resolution/Geography\",\n",
    "    \"Mathematics\": \"/Users/apoorv/Desktop/AV/Code/GAI/YT_projects/Query Resolution/Mathematics\"\n",
    "}\n",
    "\n",
    "# Dictionary to store course names and their respective .srt file paths\n",
    "course_srt_files = {}\n",
    "\n",
    "# Iterate through course folder mappings\n",
    "for course, folder_path in course_folders.items():\n",
    "    srt_files = []\n",
    "    \n",
    "    # Walk through the directory to find .srt files\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        srt_files.extend(os.path.join(root, file) for file in files if file.endswith(\".srt\"))\n",
    "    \n",
    "    # Add to dictionary if there are .srt files\n",
    "    if srt_files:\n",
    "        course_srt_files[course] = srt_files\n",
    "\n",
    "# Print or use the extracted dictionary\n",
    "# print(course_srt_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and Embedding Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/kzh744rs1t93s9wwqb108qc80000gp/T/ipykernel_929/1262629600.py:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
      "/var/folders/66/kzh744rs1t93s9wwqb108qc80000gp/T/ipykernel_929/1262629600.py:13: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# --- Part 2: Setup Persistent Vectorstore with Course SRT Files ---\n",
    "\n",
    "# Define the persistent directory for ChromaDB (replace with your desired path)\n",
    "persist_directory = \"./sample_db\"\n",
    "\n",
    "# Text splitter to break documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Initialize Chroma vectorstore with persistent directory\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"sample_course\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing in a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added course: Biology (Chunks: 8, Cost: $0.0006)\n",
      "Added course: Geography (Chunks: 7, Cost: $0.0005)\n",
      "Added course: Mathematics (Chunks: 5, Cost: $0.0004)\n",
      "\n",
      "Course Embeddings Update Completed! ðŸš€\n",
      "Total Chunks Processed: 20\n",
      "Estimated Total Tokens: 15000\n",
      "Estimated Cost: $0.0015\n",
      "Total Time Taken: 6.08 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# OpenAI Pricing (adjust based on the model being used)\n",
    "COST_PER_1K_TOKENS = 0.0001  # Cost per 1K tokens for 'text-embedding-ada-002'\n",
    "TOKENS_PER_CHUNK_ESTIMATE = 750  # Approximate tokens per 1000-character chunk\n",
    "\n",
    "# Track total tokens and cost\n",
    "total_tokens = 0\n",
    "total_cost = 0\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Add new courses to the vectorstore if they don't already exist\n",
    "for course, srt_list in course_srt_files.items():\n",
    "    # Check if the course already exists in the vectorstore\n",
    "    existing_docs = vectorstore._collection.get(where={\"course\": course})\n",
    "    if not existing_docs['ids']:\n",
    "        # Course not found, add it\n",
    "        srt_texts = [extract_text_from_srt(srt) for srt in srt_list]\n",
    "        course_text = \"\\n\\n\\n\\n\".join(srt_texts)  # Join SRT texts with four new lines\n",
    "        doc = Document(page_content=course_text, metadata={\"course\": course})\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        \n",
    "        # Estimate cost before adding documents\n",
    "        chunk_count = len(chunks)\n",
    "        batch_tokens = chunk_count * TOKENS_PER_CHUNK_ESTIMATE\n",
    "        batch_cost = (batch_tokens / 1000) * COST_PER_1K_TOKENS\n",
    "        total_tokens += batch_tokens\n",
    "        total_cost += batch_cost\n",
    "        \n",
    "        vectorstore.add_documents(chunks)\n",
    "        print(f\"Added course: {course} (Chunks: {chunk_count}, Cost: ${batch_cost:.4f})\")\n",
    "    else:\n",
    "        print(f\"Course already exists: {course}\")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Display cost and time\n",
    "print(f\"\\nCourse Embeddings Update Completed! ðŸš€\")\n",
    "print(f\"Total Chunks Processed: {total_tokens // TOKENS_PER_CHUNK_ESTIMATE}\")\n",
    "print(f\"Estimated Total Tokens: {total_tokens}\")\n",
    "print(f\"Estimated Cost: ${total_cost:.4f}\")\n",
    "print(f\"Total Time Taken: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Understanding and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define retrieval tool with metadata filtering\n",
    "def retrieve_course_materials(query: str, course = course):\n",
    "    \"\"\"Retrieves course materials filtered by course name.\"\"\"\n",
    "    filter_dict = {\"course\": course}\n",
    "    results = vectorstore.similarity_search(query, k=3, filter=filter_dict)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA, or deoxyribonucleic acid, is the fundamental molecule that carries genetic information in all living organisms. It is composed of two long strands forming a double helix, a structure first described by Watson and Crick. The strands are made up of nucleotide bases: adenine, thymine, cytosine, and guanine, which pair specifically. DNA replication ensures that genetic information is faithfully copied before cell division occurs. Mutations can occur during replication or due to environmental factors, affecting the sequence and function of genes. Cells have intricate repair mechanisms to correct errors, maintaining the integrity of the genome. Gene expression involves transcription of DNA into RNA, which is then translated into proteins that perform cellular functions. Genetic diversity arises from processes like recombination and mutation, driving evolution and adaptation. Modern biotechnology uses DNA sequencing and genetic engineering in fields such as medicine, agriculture, and\n",
      "\n",
      "arises from processes like recombination and mutation, driving evolution and adaptation. Modern biotechnology uses DNA sequencing and genetic engineering in fields such as medicine, agriculture, and forensic science. Understanding DNA has revolutionized biology, leading to breakthroughs in diagnostics, treatment, and personalized medicine.\n",
      "\n",
      "The cell cycle is a highly regulated series of events that lead to cell growth and division. It is divided into distinct phases: G1 (cell growth), S (DNA synthesis), G2 (preparation for mitosis), and M (mitosis). During the G1 phase, the cell grows and accumulates resources necessary for DNA replication. In the S phase, the entire genome is replicated, ensuring each daughter cell receives a complete set of chromosomes. The G2 phase involves further growth and preparation, where the cell checks for DNA errors before division. Mitosis, the M phase, is where the cellâ€™s nucleus divides, followed by cytokinesis which splits the cytoplasm. Cell cycle checkpoints act as quality control, ensuring DNA is replicated correctly and damage is repaired. Failures in these regulatory checkpoints can lead to uncontrolled cell division and cancer. Modern research explores cell cycle regulators to develop targeted therapies for cancer and other diseases. The study of the cell cycle not only provides\n"
     ]
    }
   ],
   "source": [
    "course_name = \"Biology\"\n",
    "question = \"What is DNA?\"\n",
    "context = retrieve_course_materials(query=question, course= course_name)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent with a well-structured role and backstory\n",
    "query_answer_agent = Agent(\n",
    "    role = \"Learning Support Specialist\",\n",
    "    goal = \"You help learners with their queries with the best possible response\",\n",
    "    backstory = \"\"\"You lead the Learners Query resolution department of an Ed tech company focussed on self paced courses on K12 school topics. You respond to learner queries related to course content, assignments, technical and administrative issues. You are polite, diplomatic and take ownership of things which could be imporved in your oragnisation. \n",
    "    \n",
    "    \"\"\",\n",
    "    verbose = False,\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_answering_task  = Task(\n",
    "    description= \"\"\"\n",
    "    Answer the learner queries to the best of your abilities. Try to keep your response concise with less than 100 words. \n",
    "    Here is the query: {query}\n",
    "\n",
    "    Here is similar content from the course extracted from subtitles, which you should use only when required: {relevant_content} .  Since this content is extracted from course subtitles, there may be spelling errors, make sure to correct these, while using this information in your response.\n",
    "\n",
    "    This is the full name of the learner: {learner_name}\n",
    "    Address each learner by their first name, if you are not sure what the first name is, simply start with Hi. \n",
    "    Also mention some appropriate and encouraging comforting lines at the end of the reponse, like \"hope you found this helpful\", \"I hope this information is useful. Keep up the great work!\", \"Glad to assist! Feel free to reach out anytime.\" etc. \n",
    "\n",
    "    If you are not sure about the answer mention - \"Sorry, I am not sure about this, I will get back to you\"\n",
    "\n",
    "    \"\"\",\n",
    "    expected_output = \"A crisp accurate response to the query\",\n",
    "    agent=query_answer_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span batch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connection.py\", line 741, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 1375, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ConnectionResetError: [Errno 54] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connection.py\", line 741, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/urllib3/util/ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 513, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 1104, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/ssl.py\", line 1375, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n",
      "    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lc/lib/python3.10/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n"
     ]
    }
   ],
   "source": [
    "# Create the Crew\n",
    "response_crew = Crew(\n",
    "    agents=[query_answer_agent],\n",
    "    tasks=[query_answering_task],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  What are some types of probability distributions?\n",
      "\n",
      "\n",
      "A:  Hi John! Some common types of probability distributions include the binomial distribution, which models the number of successes in a fixed number of independent trials; the Poisson distribution, used for counting the number of events in a fixed interval; and the normal distribution, which represents data that clusters around a mean. Understanding these distributions can greatly aid in analyzing data and making predictions. I hope this information is useful. Keep up the great work!\n",
      "\n",
      "\n",
      "\n",
      "Context: \n",
      " Probability is the mathematical study of uncertainty and likelihood. It measures the chance of an event occurring, expressed as a number between 0 and 1. The probability of an event is calculated as the ratio of favorable outcomes to total possible outcomes. Basic probability concepts include independent and dependent events, conditional probability, and Bayes' Theorem. Random variables help in modeling real-world uncertainties, using discrete and continuous probability distributions. Common probability distributions include the binomial, Poisson, and normal distributions, each with specific applications. Probability plays a crucial role in decision-making, statistics, risk assessment, and machine learning. Bayesian probability helps update beliefs based on new data and is widely used in AI and data science. Understanding probability is essential for analyzing data, predicting outcomes, and improving strategic planning.\n",
      "\n",
      "as calculating profit margins, interest rates, and physics formulas. Exponents and logarithms are advanced algebraic operations that simplify complex calculations and are essential in exponential growth models. Mastering algebra is essential for advanced studies in science, engineering, economics, and computer programming.\n",
      "\n",
      "Geometry is the study of shapes, sizes, and the properties of space. It includes the study of points, lines, angles, surfaces, and solids. Euclidean geometry, named after the ancient Greek mathematician Euclid, forms the basis of classical geometry. Triangles are one of the fundamental shapes studied in geometry, classified as equilateral, isosceles, or scalene. The Pythagorean Theorem states that in a right triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides. Circles have unique properties such as radius, diameter, circumference, and area, governed by formulas involving Ï€. 3D geometry studies shapes like spheres, cylinders, cubes, and pyramids, extending 2D principles into three-dimensional space. Transformations in geometry, such as translation, rotation, reflection, and dilation, describe how shapes change in space. Geometry has real-world applications in architecture, navigation, art, engineering, and computer graphics.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are some types of probability distributions?\"\n",
    "learner_name = \"John\" \n",
    "course_name = \"Mathematics\"\n",
    "context = retrieve_course_materials(query = question , course=course_name)\n",
    "\n",
    "response_result = response_crew.kickoff(inputs={\"query\": question, \n",
    "                                                \"relevant_content\": context,\n",
    "                                                \"learner_name\": learner_name}) \n",
    "print('Q: ', question)\n",
    "print('\\n')\n",
    "print('A: ', response_result)\n",
    "print('\\n\\n')\n",
    "print('Context: \\n', context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To upgrade this system further: \n",
    "1. Explore different methods of chunking\n",
    "2. Query Enhancement\n",
    "3. Image Processing Capability\n",
    "4. Finding different approaches to select relevant documents.\n",
    "5. Inlcude past discussions in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
